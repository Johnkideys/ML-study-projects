{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data/AQI_data_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City          0\n",
       "Date          0\n",
       "PM2.5         0\n",
       "PM10          0\n",
       "NO            0\n",
       "NO2           0\n",
       "NOx           0\n",
       "NH3           0\n",
       "CO            0\n",
       "SO2           0\n",
       "O3            0\n",
       "Benzene       0\n",
       "Toluene       0\n",
       "Xylene        0\n",
       "AQI           0\n",
       "AQI_Bucket    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>83.13</td>\n",
       "      <td>96.18</td>\n",
       "      <td>6.93</td>\n",
       "      <td>28.71</td>\n",
       "      <td>33.72</td>\n",
       "      <td>16.31</td>\n",
       "      <td>6.93</td>\n",
       "      <td>49.52</td>\n",
       "      <td>59.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.14</td>\n",
       "      <td>209.0</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>79.84</td>\n",
       "      <td>96.18</td>\n",
       "      <td>13.85</td>\n",
       "      <td>28.68</td>\n",
       "      <td>41.08</td>\n",
       "      <td>16.31</td>\n",
       "      <td>13.85</td>\n",
       "      <td>48.49</td>\n",
       "      <td>97.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.81</td>\n",
       "      <td>328.0</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>94.52</td>\n",
       "      <td>96.18</td>\n",
       "      <td>24.39</td>\n",
       "      <td>32.66</td>\n",
       "      <td>52.61</td>\n",
       "      <td>16.31</td>\n",
       "      <td>24.39</td>\n",
       "      <td>67.39</td>\n",
       "      <td>111.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.67</td>\n",
       "      <td>514.0</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>135.99</td>\n",
       "      <td>96.18</td>\n",
       "      <td>43.48</td>\n",
       "      <td>42.08</td>\n",
       "      <td>84.57</td>\n",
       "      <td>16.31</td>\n",
       "      <td>43.48</td>\n",
       "      <td>75.23</td>\n",
       "      <td>102.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>25.87</td>\n",
       "      <td>782.0</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>178.33</td>\n",
       "      <td>96.18</td>\n",
       "      <td>54.56</td>\n",
       "      <td>35.31</td>\n",
       "      <td>72.80</td>\n",
       "      <td>16.31</td>\n",
       "      <td>54.56</td>\n",
       "      <td>55.04</td>\n",
       "      <td>107.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35.61</td>\n",
       "      <td>914.0</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City        Date   PM2.5   PM10     NO    NO2    NOx    NH3     CO  \\\n",
       "0  Ahmedabad  2015-01-29   83.13  96.18   6.93  28.71  33.72  16.31   6.93   \n",
       "1  Ahmedabad  2015-01-30   79.84  96.18  13.85  28.68  41.08  16.31  13.85   \n",
       "2  Ahmedabad  2015-01-31   94.52  96.18  24.39  32.66  52.61  16.31  24.39   \n",
       "3  Ahmedabad  2015-02-01  135.99  96.18  43.48  42.08  84.57  16.31  43.48   \n",
       "4  Ahmedabad  2015-02-02  178.33  96.18  54.56  35.31  72.80  16.31  54.56   \n",
       "\n",
       "     SO2      O3  Benzene  Toluene  Xylene    AQI AQI_Bucket  \n",
       "0  49.52   59.76     0.02     0.00    3.14  209.0       Poor  \n",
       "1  48.49   97.07     0.04     0.00    4.81  328.0  Very Poor  \n",
       "2  67.39  111.33     0.24     0.01    7.67  514.0     Severe  \n",
       "3  75.23  102.70     0.40     0.04   25.87  782.0     Severe  \n",
       "4  55.04  107.38     0.46     0.06   35.61  914.0     Severe  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Columns to encode\n",
    "columns_to_encode = ['City', 'AQI_Bucket']\n",
    "# Encode specified columns\n",
    "for column in columns_to_encode:\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "\n",
    "# Split dataset into features (X) and target variable (y)\n",
    "X = df.drop(columns=['AQI_Bucket','Date','AQI', 'City']) \n",
    "y = df['AQI_Bucket']\n",
    "\n",
    "# Apply a log transformation to your features (X)\n",
    "X_log_transformed = np.log1p(X)\n",
    "\n",
    "# Split the log-transformed data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log_transformed, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>3.769768</td>\n",
       "      <td>4.576565</td>\n",
       "      <td>1.680828</td>\n",
       "      <td>2.798500</td>\n",
       "      <td>2.845491</td>\n",
       "      <td>2.851284</td>\n",
       "      <td>0.708036</td>\n",
       "      <td>1.781709</td>\n",
       "      <td>3.613347</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>1.111858</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>4.536570</td>\n",
       "      <td>5.129425</td>\n",
       "      <td>3.201933</td>\n",
       "      <td>3.921973</td>\n",
       "      <td>4.305011</td>\n",
       "      <td>3.074543</td>\n",
       "      <td>0.770108</td>\n",
       "      <td>2.532903</td>\n",
       "      <td>3.417727</td>\n",
       "      <td>1.915451</td>\n",
       "      <td>1.520607</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>4.068343</td>\n",
       "      <td>4.430698</td>\n",
       "      <td>2.332144</td>\n",
       "      <td>2.399712</td>\n",
       "      <td>3.008155</td>\n",
       "      <td>2.560323</td>\n",
       "      <td>0.488580</td>\n",
       "      <td>2.024193</td>\n",
       "      <td>3.473518</td>\n",
       "      <td>1.121678</td>\n",
       "      <td>1.163151</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021</th>\n",
       "      <td>3.830596</td>\n",
       "      <td>4.576565</td>\n",
       "      <td>1.868721</td>\n",
       "      <td>1.987874</td>\n",
       "      <td>1.166271</td>\n",
       "      <td>2.851284</td>\n",
       "      <td>1.018847</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>3.981362</td>\n",
       "      <td>1.166271</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>3.287655</td>\n",
       "      <td>4.154655</td>\n",
       "      <td>2.283402</td>\n",
       "      <td>3.369018</td>\n",
       "      <td>3.439777</td>\n",
       "      <td>2.595255</td>\n",
       "      <td>0.770108</td>\n",
       "      <td>2.142416</td>\n",
       "      <td>3.529591</td>\n",
       "      <td>0.667829</td>\n",
       "      <td>3.565581</td>\n",
       "      <td>0.883768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PM2.5      PM10        NO       NO2       NOx       NH3        CO  \\\n",
       "7125   3.769768  4.576565  1.680828  2.798500  2.845491  2.851284  0.708036   \n",
       "20041  4.536570  5.129425  3.201933  3.921973  4.305011  3.074543  0.770108   \n",
       "3256   4.068343  4.430698  2.332144  2.399712  3.008155  2.560323  0.488580   \n",
       "18021  3.830596  4.576565  1.868721  1.987874  1.166271  2.851284  1.018847   \n",
       "5140   3.287655  4.154655  2.283402  3.369018  3.439777  2.595255  0.770108   \n",
       "\n",
       "            SO2        O3   Benzene   Toluene    Xylene  \n",
       "7125   1.781709  3.613347  0.565314  1.111858  0.883768  \n",
       "20041  2.532903  3.417727  1.915451  1.520607  0.883768  \n",
       "3256   2.024193  3.473518  1.121678  1.163151  1.098612  \n",
       "18021  1.945910  3.981362  1.166271  0.631272  0.883768  \n",
       "5140   2.142416  3.529591  0.667829  3.565581  0.883768  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()\n",
    "# XGBoost seems to deal with NaN values better than me imputing them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set: 0.9584004024144869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1059\n",
      "           1       0.95      0.95      0.95      7084\n",
      "           2       0.97      0.92      0.95      2226\n",
      "           3       0.94      0.97      0.96      6569\n",
      "           4       1.00      1.00      1.00      1067\n",
      "           5       0.99      0.99      0.99      1875\n",
      "\n",
      "    accuracy                           0.96     19880\n",
      "   macro avg       0.97      0.96      0.97     19880\n",
      "weighted avg       0.96      0.96      0.96     19880\n",
      "\n",
      "----------------------------------------------------------\n",
      "Accuracy for testing set: 0.8088531187122736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       282\n",
      "           1       0.82      0.84      0.83      1745\n",
      "           2       0.67      0.66      0.66       555\n",
      "           3       0.84      0.87      0.86      1655\n",
      "           4       0.84      0.80      0.82       271\n",
      "           5       0.76      0.73      0.74       462\n",
      "\n",
      "    accuracy                           0.81      4970\n",
      "   macro avg       0.80      0.76      0.78      4970\n",
      "weighted avg       0.81      0.81      0.81      4970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create an XGBoost classification model\n",
    "model = XGBClassifier() \n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "# Prediction on training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy of training set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Accuracy for training set: {accuracy_train}\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"----------------------------------------------------------\")\n",
    "# Evaluate the model's performance using accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy for testing set: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: None\n",
      "Current Max Depth: None\n",
      "Current Max Depth: None\n"
     ]
    }
   ],
   "source": [
    "# Access hyperparameters of the XGBoost model\n",
    "learning_rate = model.get_params()['learning_rate']\n",
    "max_depth = model.get_params()['max_depth']\n",
    "n_estimators = model.get_params()['n_estimators']\n",
    "\n",
    "# Print the current hyperparameter values\n",
    "print(f\"Current Learning Rate: {learning_rate}\")\n",
    "print(f\"Current Max Depth: {max_depth}\")\n",
    "print(f\"Current Max Depth: {n_estimators}\")\n",
    "\n",
    "# Print values will be None if default values left in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': 3, 'learning_rate': 0.5}\n",
      "Best Accuracy:  0.7831991951710261\n",
      "Accuracy for training set: 0.8372233400402415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1059\n",
      "           1       0.95      0.95      0.95      7084\n",
      "           2       0.97      0.92      0.95      2226\n",
      "           3       0.94      0.97      0.96      6569\n",
      "           4       1.00      1.00      1.00      1067\n",
      "           5       0.99      0.99      0.99      1875\n",
      "\n",
      "    accuracy                           0.96     19880\n",
      "   macro avg       0.97      0.96      0.97     19880\n",
      "weighted avg       0.96      0.96      0.96     19880\n",
      "\n",
      "----------------------------------------------------------\n",
      "Accuracy for testing set: 0.7806841046277666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       282\n",
      "           1       0.82      0.84      0.83      1745\n",
      "           2       0.67      0.66      0.66       555\n",
      "           3       0.84      0.87      0.86      1655\n",
      "           4       0.84      0.80      0.82       271\n",
      "           5       0.76      0.73      0.74       462\n",
      "\n",
      "    accuracy                           0.81      4970\n",
      "   macro avg       0.80      0.76      0.78      4970\n",
      "weighted avg       0.81      0.81      0.81      4970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With Hyperparameter tuning and feature selection\n",
    "\n",
    "# Use certain columns\n",
    "X = X[['PM2.5','PM10','NO','NO2','CO','NOx','SO2']]\n",
    "# Apply a log transformation to your features (X)\n",
    "X_log_transformed = np.log1p(X)\n",
    "# Split the log-transformed data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.5],\n",
    "    'max_depth': range(2, 5) # 10\n",
    "    # Add more hyperparameters here\n",
    "    # max_node\n",
    "}\n",
    "\n",
    "# Define the number of random iterations\n",
    "n_iter = 5  \n",
    "\n",
    "# Perform the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter,\n",
    "    scoring='accuracy',  # Use the appropriate scoring metric\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    #n_jobs=-1  # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Fit the random search on your training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator (model) with the best hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters and corresponding performance\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy: \", random_search.best_score_)\n",
    "\n",
    "# Make predictions on the training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy of training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Accuracy for training set: {accuracy_train}\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"----------------------------------------------------------\")\n",
    "# Calculate accuracy of testing set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy for testing set: {test_accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 0.5\n",
      "Current Max Depth: 3\n",
      "Current Max Depth: None\n"
     ]
    }
   ],
   "source": [
    "# Access hyperparameters of the XGBoost model\n",
    "learning_rate = best_model.get_params()['learning_rate']\n",
    "max_depth = best_model.get_params()['max_depth']\n",
    "n_estimators = best_model.get_params()['n_estimators']\n",
    "\n",
    "# Print the current hyperparameter values\n",
    "print(f\"Current Learning Rate: {learning_rate}\")\n",
    "print(f\"Current Max Depth: {max_depth}\")\n",
    "print(f\"Current Max Depth: {n_estimators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': 4, 'learning_rate': 0.5}\n",
      "Best Accuracy:  0.8014084507042254\n",
      "Accuracy for training set: 0.9131287726358149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1059\n",
      "           1       0.95      0.95      0.95      7084\n",
      "           2       0.97      0.92      0.95      2226\n",
      "           3       0.94      0.97      0.96      6569\n",
      "           4       1.00      1.00      1.00      1067\n",
      "           5       0.99      0.99      0.99      1875\n",
      "\n",
      "    accuracy                           0.96     19880\n",
      "   macro avg       0.97      0.96      0.97     19880\n",
      "weighted avg       0.96      0.96      0.96     19880\n",
      "\n",
      "----------------------------------------------------------\n",
      "Accuracy for testing set: 0.8024144869215292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       282\n",
      "           1       0.82      0.84      0.83      1745\n",
      "           2       0.67      0.66      0.66       555\n",
      "           3       0.84      0.87      0.86      1655\n",
      "           4       0.84      0.80      0.82       271\n",
      "           5       0.76      0.73      0.74       462\n",
      "\n",
      "    accuracy                           0.81      4970\n",
      "   macro avg       0.80      0.76      0.78      4970\n",
      "weighted avg       0.81      0.81      0.81      4970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With Hyperparameter tuning \n",
    "\n",
    "\n",
    "# Split dataset into features (X) and target variable (y)\n",
    "X = df.drop(columns=['AQI_Bucket','Date','AQI', 'City']) \n",
    "y = df['AQI_Bucket']\n",
    "\n",
    "# Apply a log transformation to your features (X)\n",
    "X_log_transformed = np.log1p(X)\n",
    "# Split the log-transformed data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# the XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.5],\n",
    "    'max_depth': range(2, 5) # 10\n",
    "    # Add more hyperparameters here\n",
    "    # max_node\n",
    "}\n",
    "\n",
    "# Define the number of random iterations\n",
    "n_iter = 5  \n",
    "\n",
    "# Perform the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter,\n",
    "    scoring='accuracy',  # Use the appropriate scoring metric\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    #n_jobs=-1  # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Fit the random search on your training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator (model) with the best hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters and corresponding performance\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy: \", random_search.best_score_)\n",
    "\n",
    "# Make predictions on the training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy of training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Accuracy for training set: {accuracy_train}\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"----------------------------------------------------------\")\n",
    "# Calculate accuracy of testing set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy for testing set: {test_accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_first_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
